## 介绍

问题【1】：关于原型图用途
在传统工作流中，Axure原型图的核心功能是视觉与交互设计展示，而非作为测试用例设计的直接输入。本系统的核心假设是：一个足够详尽、遵循特定规范的Axure原型，其静态HTML产物包含了可被机器解析的、结构化的需求信息。系统并非将原型图作为交互模型来“运行”，而是将其作为一份机器可读的需求文档来“解析”。

工作机制如下：

输入: **系统接收的是Axure导出的HTML、CSS和JS文件集合，而非.rp源文件或图片。**

解析: 后端服务（axureParseService.ts）使用DOM解析库（如cheerio）遍历HTML结构。它不关心页面的视觉表现，只提取结构化信息：元素类型（通过class和tag推断）、标签文本、元素ID、data-label等Axure特有的属性。

转换: 解析后的DOM结构被转换成一份结构化的JSON对象。这份JSON对象是对页面元素的“盘点清单”，例如：{ "type": "input", "name": "用户名" }, { "type": "button", "text": "登录" }。这份JSON清单随后被提交给大语言模型（LLM），LLM的任务是基于这份清单“逆向工程”出一份产品需求文档（PRD）。系统并未改变原型图用于“设计展示”的本质。它只是利用了Axure导出产物的结构化特性，将其作为一种替代性的、不规范但可解析的需求规约来源。其有效性完全依赖于原型制作的规范性和详尽程度。

问题【2】：关于数据库结构的强制性

报告中涉及的数据库表结构是强制性的，缺少这些表，相关功能将完全无法运行。系统的数据持久化、版本控制和AI生成流程都依赖于此结构。

核心新增表结构解析：

ai_generation_sessions:

用途: 记录每一次从“上传Axure”到“生成用例”的完整会话。

关键字段: id (会话ID), user_id, axure_filename, requirement_doc (AI生成的需求文档), pre_analysis_result (智能补全分析结果), enhanced_data (用户确认后的数据)。

必要性: 确保所有AI生成过程可追溯、可审计。没有此表，无法在多步骤流程中传递上下文。

functional_test_cases:

用途: 存储高级别的测试用例，对应“测试目的”。它是一个容器。

关键字段: id, name, system, module, ai_session_id (关联生成会话)。

必要性: 组织和管理测试点，形成测试用例的层级结构。

functional_test_points:

用途: 存储具体的、可执行的测试点，是测试用例的最小单元。

关键字段: id, test_case_id (关联functional_test_cases), test_point_name, steps, expected_result, risk_level。

必要性: 这是最终产物的核心存储单元。一个functional_test_case包含多个functional_test_points。

关于向量数据库 (Qdrant):

用途: 此数据库用于实现RAG（检索增强生成）功能，是系统的增强层而非核心层。

工作机制: 它将业务规则、历史缺陷（pitfall）、风险场景等知识条目，通过Embedding模型（如阿里云通义）转换为向量并存储。在生成测试点时，系统会根据当前上下文在向量数据库中进行语义搜索，找到最相关的知识，并将其注入到LLM的提示词中，以生成更专业、更具针对性的测试点。

必要性: 如果不部署Qdrant或相关配置，系统仍然可以生成测试用例，但质量会显著下降，无法利用历史经验，也无法自动生成边界、异常和风险场景的测试。它将退化为一个纯粹基于原型内容推断的生成器。

问题【3】：“成熟原型”与“任意HTML”的界定

你的理解是正确的，系统接收的是HTML输入。然而，“理论上可以把任何HTML丢进去”这一推论是不成立的。

原因如下：

解析器高度耦合: axureParseService.ts中的解析逻辑是为Axure导出的特定HTML结构量身定制的。它依赖于Axure生成的特定class名称、ID格式和data-*属性。

示例: 系统通过查找div.ax_default.label来识别按钮和标签，并通过文本长度和关键词来区分两者。一个标准的网页（如<div><button>提交</button></div>）不包含这种结构，会导致按钮识别失败。

结构化假设: 系统假设HTML内容在结构上反映了功能的组织。例如，它会假定“查询”按钮附近的输入框是查询条件，而“保存”按钮附近的输入框是表单字段。普通网页的布局可能不遵循这种简单的逻辑。

“成熟原型”的定义: 在此项目的语境下，“成熟”指的不是原型在设计评审流程中的状态，而是其内容的详尽和规范程度。一个“成熟”的Axure原型意味着：

所有可交互元素（按钮、输入框）都已绘制。

所有元素的标签文本都已正确填写。

页面之间的跳转关系已通过交互链接建立。

复杂的业务规则已通过注释或文本块的形式在原型中说明。

结论: 将任意网站的HTML输入此系统，解析器会因找不到预期的结构模式而失败，或提取出大量无意义的、非结构化的元素，导致后续AI生成的需求文档质量极低或完全不可用。该系统对输入源的格式有强依赖性，并不具备通用HTML页面的解析能力。

问题【4】: 系统完整工作流程详解

以下为系统从接收用户上传到最终保存测试用例的完整、详细步骤分解。

步骤 1.1: 用户上传与信息补充

输入: 用户在前端页面 (/functional-test-cases/generator) 上传一个或多个文件（必须包含至少一个.html文件），这些文件是Axure导出的产物。同时，用户输入系统名称、模块名称，并可选填写补充业务规则。

数据示例:

文件: 订单管理.html, data.js

系统名称: 电商后台

模块名称: 订单管理

补充规则: 订单金额超过10000元需要财务审批

步骤 1.2: 后端文件解析 (axureParseService.ts)

过程: 后端接收到文件后，首先识别出主HTML文件。随后，使用DOM解析库（cheerio）遍历HTML的树状结构。

提取逻辑:

元素识别: 查找带有Axure特定class（如 ax_default label, ax_default text_field）或tag（input, select）的元素。

文本提取: 提取元素的可见文本，如按钮名“查询”、输入框标签“订单号”。

类型推断: 根据元素的class、tag和文本内容，将其初步分类为 button, input, select, div 等。

业务规则提取: 专门查找长文本块（div），特别是包含“规则”、“说明”、“备注”或特定关键词（审核、校验、拦截）的文本，作为业务规则的原始素材。

输出: 一个结构化的JSON对象，包含了页面上所有被识别的元素及其属性。

数据示例:

HTML片段: <div id="u123" class="ax_default label"><div class...><p><span>查询</span></p>...</div>

解析结果 (JSON片段): { "id": "u123", "type": "button", "text": "查询" }

步骤 1.3: AI生成需求文档初稿 (functionalTestCaseAIService.ts)

过程: 将步骤1.2中生成的JSON对象、用户输入的项目信息、以及HTML文件中的长文本规则，全部打包成一个巨大的提示词（Prompt）发送给大语言模型（LLM）。

AI任务: 提示词指示AI扮演一名“需求分析专家”，其任务是：

理解页面类型: 根据元素组合（如：有“查询”按钮和表格 -> 列表页；有“保存”按钮和输入框 -> 表单页）判断页面类型。

功能模块化: 将离散的元素（输入框、按钮）组合成有业务意义的功能模块（如“查询条件区”、“操作按钮区”）。

结构化输出: 按照预设的Markdown模板，生成包含页面布局、查询条件、列表字段、操作按钮、业务规则等章节的需求文档（PRD）。

输出: 一份Markdown格式的文本。

数据示例:

输入 (JSON片段): [{ "type": "input", "name": "订单号" }, { "type": "button", "text": "查询" }]

输出 (Markdown片段):

code
Markdown
download
content_copy
expand_less
#### 1.1.2 查询条件
| 字段名 | 控件类型 | 必填 |
|---|---|---|
| 订单号 | 文本框 | 否 |

步骤 1.4: 用户审核需求文档 (第一个关键节点)

过程: 后端将生成的Markdown文档返回给前端，前端使用编辑器（MarkdownEditor.tsx）将其展示给用户。

用户操作: 用户可以阅读、编辑、补充或修正这份AI生成的需求文档。例如，补充AI未能推断出的隐藏业务规则，或修正AI对字段的错误理解。

输出: 一份经过用户确认和优化的最终版需求文档。这份文档是后续所有生成步骤的唯一依据。

步骤 2.1: 阶段一 - AI拆分测试模块

输入: 用户审核过的最终版需求文档。

过程: 用户点击“生成测试用例”后，前端将需求文档全文提交给后端。后端再次调用LLM。

AI任务: 提示词指示AI扮演一名“测试架构师”，将需求文档按功能或章节拆分为高级别的测试模块。

输出: 一个测试模块列表。

数据示例:

输入: 包含“查询条件”、“列表展示”、“操作按钮”等章节的需求文档。

输出 (JSON): [{ "id": "module-1", "name": "查询条件测试" }, { "id": "module-2", "name": "列表数据与操作测试" }]

步骤 2.2: 阶段二 - AI生成测试目的

输入: 用户从模块列表中选择一个或多个模块。

过程: 对于用户选择的每个模块，后端再次调用LLM，并将该模块关联的需求文档内容一并传入。

AI任务: 提示词指示AI扮演一名“高级测试工程师”，为指定的测试模块设计更高层级的测试目的（Test Purpose）。

输出: 每个模块下生成2-8个测试目的。

数据示例:

输入: “查询条件测试”模块。

输出 (JSON): [{ "id": "purpose-1", "name": "单条件查询验证" }, { "id": "purpose-2", "name": "多条件组合查询验证" }, { "id": "purpose-3", "name": "边界值与异常输入测试" }]

步骤 2.3: 阶段三 - AI生成测试点 (RAG增强)

这是整个系统技术含金量最高的一步。

输入: 用户从测试目的列表中选择一个或多个目的。

过程: 对于用户选择的每个测试目的，后端执行以下RAG流程：

构建查询: 将测试目的的名称和描述（如“边界值与异常输入测试”）以及相关的需求文档片段组合成一个语义查询。

向量化: 调用Embedding模型（如阿里云通义）将该查询文本转换为一个1024维的向量。

语义检索 (testCaseKnowledgeBase.ts): 使用此向量在Qdrant向量数据库的对应系统集合（test_knowledge_{系统名称}）中进行相似度搜索。

知识获取: Qdrant返回最相似的知识条目，例如，对于“边界值测试”，可能会检索到：

历史踩坑点: “特殊字符 " 和 ' 未转义导致查询失败”

风险场景: “SQL注入风险：输入 ' OR '1'='1 验证”

业务规则: “订单号长度必须为18位”

上下文增强: 将这些检索到的知识条目格式化后，注入到一个新的、最终的LLM提示词中。

最终生成调用: 将测试目的、相关需求文档内容、以及增强的知识上下文，一同发送给LLM。

AI任务: 提示词指示AI扮演一名“资深测试专家”，基于所有上下文，生成具体的、包含操作步骤、预期结果和风险等级的测试点（Test Point）。

输出: 一个包含多个测试点的完整测试用例JSON对象。

数据示例:

输入: “边界值与异常输入测试” + RAG检索到的知识。

输出 (JSON片段):

code
JSON
download
content_copy
expand_less
{
  "testPointName": "SQL注入风险测试",
  "steps": "1. 在订单号输入框输入 ' OR '1'='1\n2. 点击查询按钮",
  "expectedResult": "系统应提示查询无结果或参数无效，不应返回所有数据或报错",
  "riskLevel": "high"
}

步骤 3.1: 草稿箱展示与审核 (最后一个关键节点)

过程: 后端将生成的测试用例（包含多个测试点）返回给前端。前端以卡片形式在“草稿箱”中展示每个测试用例。

用户操作:

预览: 用户可以点击查看每个测试用例的详细测试点。

编辑: 用户可以在弹窗中直接修改测试点的步骤、预期结果等。

选择: 用户通过复选框选择最终需要保存的测试用例。

步骤 3.2: 保存到数据库

过程: 用户点击“保存到用例库”后，前端将所有选中的测试用例JSON对象批量提交给后端。

后端操作:

启动一个数据库事务。

为每个提交的测试用例，在 functional_test_cases 表中创建一条主记录。

对于该用例下的每个测试点，在 functional_test_points 表中创建一条记录，并关联到主记录的ID。

事务提交。

输出: 数据被持久化到MySQL数据库中，流程结束。用户被重定向到功能测试用例列表页面，可以看到刚刚保存的所有用例和测试点。


**关于系统定位：**
是一个专用于测试用例设计与生成阶段的辅助工具集，即一个“工作台”，它并非一个全面的、端到端的测试管理平台（如Jira+Xray, TestRail），因为它**不直接处理测试执行跟踪、缺陷管理或测试报告的完整生命周期**。

其核心功能限定在以下范围内：

原型解析: 将Axure原型HTML作为结构化数据源进行解析。

需求生成: 基于解析结果，利用LLM生成一份可读的需求文档初稿。

用例生成: 基于需求文档，通过三阶段渐进式流程生成测试模块、测试目的和具体的测试点。

草稿审核: 在“AI生成器”页面 (/functional-test-cases/generator) 的第三个步骤（生成用例）中，用于临时展示和管理AI生成结果的前端状态容器。供用户审核、编辑和选择生成的用例。

它仅存在于AI生成器页面的第三步界面中。临时性: 其内容存储在前端应用的内存状态（React State）中，并可能缓存到浏览器的LocalStorage以防止意外关闭。这些数据在用户点击“保存到用例库”或离开页面后即被清空或失效。交互性: 用户在此区域内对AI生成的测试用例卡片进行交互，包括：通过复选框选择或取消选择。点击卡片打开详情弹窗（TestCaseDetailModal.tsx）进行编辑。触发“重新生成”、“优化”等批量操作。它的唯一目的是作为将AI生成结果持久化到数据库（functional_test_cases 和 functional_test_points 表）之前的缓冲区和审核区。

**关于输入输出与人类的交互流程**
完全通过其Web前端界面与用户进行交互。以下是完整的交互路径：

输入 (Input):

动作: 用户通过前端界面 (src/components/ai-generator/MultiFileUpload.tsx 组件) 上传文件。

人类交互: 用户将本地的Axure导出文件夹（包含.html和.js文件）拖拽到上传区域，或通过文件选择器选取。同时，在表单中输入“系统名称”、“模块名称”等文本信息。

中间输出 / 交互 (Intermediate Output / Interaction):

动作: 系统完成解析后，输出AI生成的需求文档初稿。

人类交互: 用户在网页上的一个富文本编辑器（src/components/ai-generator/MarkdownEditor.tsx）中阅读和编辑这份Markdown格式的文档。这是第一个关键的人机交互审核点。

最终输出 / 交互 (Final Output / Interaction):

动作: 在用户确认需求文档后，系统在“草稿箱”区域以卡片形式（src/components/ai-generator/DraftCaseCard.tsx）分批输出生成的测试用例。

人类交互: 用户浏览这些卡片，通过点击复选框进行选择。如果需要修改，可以点击卡片打开一个模态框（src/components/ai-generator/TestCaseDetailModal.tsx）来编辑测试点的具体步骤和预期结果。这是第二个关键的人机交互审核点。

持久化 (Persistence):

动作: 用户完成选择和编辑后，点击“保存到用例库”按钮。

人类交互: 单次点击操作，触发数据持久化。

最终结果展示 (Final Result Display):

动作: 系统将用户保存的测试用例持久化到数据库后，通常会跳转到功能测试用例列表页面 (/functional-test-cases)。

人类交互: 用户在该页面以表格或列表的形式，查看已成为正式记录的、可供后续使用的测试用例。

**用户系统、角色与权限**
系统具备完整的用户登录、角色与权限管理机制。

4.1 用户登录系统
存在性: 是。文件结构中明确包含用户认证相关模块：

server/routes/auth.ts (登录API路由)

server/services/authService.ts (登录逻辑服务)

src/pages/Login.tsx (前端登录页面)

src/contexts/AuthContext.tsx (前端认证状态管理)

机制: 系统基于JWT (JSON Web Token) 实现会话管理。用户登录成功后，前端会存储一个token用于后续所有API请求的身份验证。

4.2 目标用户角色

主要用户: 根据需求文档 docs/tech-docs/Axure自动生成测试用例-需求文档-V2.0-最终版.md 中的“1.4 用户角色”章节定义，系统的主要用户是测试工程师、QA工程师。

次要用户: 产品经理和开发工程师被定义为次要用户，他们可以使用系统来了解测试覆盖范围和测试场景。

4.3 角色与权限

存在性: 是。系统定义了不同级别的权限，主要体现在数据隔离上。

证据:

数据库层面: prisma/schema.prisma 文件中的 users 表定义了 is_super_admin (布尔型) 字段，表明存在超级管理员角色。同时，users, test_cases, functional_test_cases 等多个表都包含 department (部门) 字段，这是实现数据隔离的基础。

代码层面: 后端路由和服务中存在基于用户角色和部门进行数据过滤的逻辑。例如，在获取测试用例列表时，会检查用户是否为 isSuperAdmin。如果不是，查询将额外附加 WHERE department = '用户的部门' 的条件。

定义的角色:

超级管理员 (Super Admin): 拥有最高权限，可以查看和管理所有部门的测试数据。

普通用户 (Regular User): 权限受其所属 department 字段限制，只能查看和管理自己所在部门的测试用例和测试套件。


**系统中AI的角色、数量及数据处理流程**

系统中存在两个不同阶段、承担不同任务的LLM调用，而非单一AI。
AI #1: 需求文档生成器 (PRD Generator)
触发阶段: 用户上传Axure原型文件后。
输入: axureParseService.ts 服务输出的结构化JSON对象。此解析过程完全由确定性代码（cheerio库）完成，不涉及任何AI。它遍历HTML DOM，提取元素、文本和Axure特有属性，生成一份对页面元素的“盘点清单”。
任务: 此AI的核心任务是将这份离散的、缺乏业务上下文的元素清单，“逆向工程”成一份人类可读的、结构化的Markdown格式产品需求文档（PRD）。它负责推断页面类型（列表页/表单页）、将元素组织成功能模块（查询区/操作区），并初步整理业务规则。
输出: Markdown文本格式的PRD初稿。

AI #2: 测试点生成器 (Test Point Generator)

触发阶段: 在我（作为用户）审核并确认了AI #1生成的PRD之后。
输入: 经我人工审核和修正后的最终版PRD中的特定章节内容，以及一个明确的“测试目的”（例如，“验证单条件查询功能”）。
任务: 此AI的核心任务是扮演一名“资深测试专家”，基于给定的需求文档片段和测试目的，设计出具体的、可执行的测试点。每个测试点都包含明确的steps（操作步骤）和expectedResult（预期结果）。这才是第三方方案中“生成步骤”所指的环节。
增强机制 (RAG): 在调用此AI之前，系统会先执行一次RAG（检索增强生成）流程。它将“测试目的”和相关需求文本作为查询，在Qdrant向量数据库中搜索相关的历史经验（如业务规则、历史缺陷），并将检索到的知识注入到此AI的提示词中，以提高生成测试点的专业性和覆盖度。
输出: 结构化的JSON对象，其中包含一个测试点数组 (testPoints)。

结论: Axure原型的解析是100%的确定性代码，其准确性应通过传统的单元测试和集成测试来保证，而非AI评估。第三方方案真正想要验证的，应该是**AI #2（测试点生成器）**的输出质量。

==================================
## 哪些是亮点，哪些是行业普遍操作？

（哪些是标准的合格的开发者应该主动做的，而不是真正的技术挑战或设计亮点。

1. 基于MCP协议的浏览器自动化抽象层
1.1 设计动因与解决的问题

****在构建基于LLM的自动化测试执行器时，核心挑战在于如何规范化模型的输出。直接让LLM生成Playwright代码存在极高的安全风险（代码注入）和不稳定性（幻觉）。
决策逻辑： 我们采用了Model Context Protocol (MCP) 作为中间抽象层，而非直接生成代码。
**行业普遍实践部分：**
不直接生成和执行LLM产出的代码：这是最基本的安全常识。任何允许LLM直接生成可执行代码而没有严格沙箱和审查机制的系统，都存在严重的安全漏洞。选择一个抽象层（无论是MCP、API调用还是其他形式的工具调用）是避免代码注入风险的标准做法，是必须做的，而不是一个亮点。
使用Schema验证：对任何外部输入（包括LLM的输出）使用Zod、Pydantic或类似的工具进行严格的Schema验证，是构建健壮系统的标准操作。这确保了数据结构的确定性，防止了格式错误。
将浏览器操作原子化为一系列“工具”，并设计这些工具的接口，这个工具集的设计本身是有价值的

上下文管理： 解决了Playwright上下文与LLM Token窗口之间的状态同步问题，通过 list_tools 动态暴露当前页面可用的操作。

1.2 关键代码引用： PlaywrightMcpClient 如何实现MCP协议的工具调用请求，将抽象的工具名映射为通过传输层发送的标准化JSON-RPC消息。

code
TypeScript
download
content_copy
expand_less
// 文件: backend/src/services/mcp/PlaywrightMcpClient.ts

async callTool(toolName: string, toolArgs: any): Promise<any> {
    // 构建符合MCP规范的工具调用请求
    // 这一步将业务逻辑与底层传输解耦，确保发送的数据符合 CallToolRequestSchema 契约
    const result = await this.client.request(
      {
        method: "tools/call", // 标准MCP方法名
        params: {
          name: toolName,     // 映射到 Playwright 的具体操作（如 'click'）
          arguments: toolArgs // 经过 Zod 验证的参数对象
        },
      },
      CallToolRequestSchema // Zod Schema 用于运行时响应验证
    );

    return result;
}
**2. 递归式DOM快照与选择器解析策略**
2.1 设计动因与解决的问题

LLM无法直接“看”到渲染后的网页。传统的做法是将整个HTML传给LLM，但这会导致Token溢出且包含大量无意义的样式噪音。
决策逻辑： 设计了 AITestParser 服务，实施了“快照压缩-意图匹配”策略。

**行业普遍实践部分：**
对输入数据进行预处理和清洗：将原始HTML直接喂给LLM是极其低效且昂贵的做法。提取关键信息、移除噪音（如样式、脚本）是任何RAG或信息提取应用中的标准步骤。这属于数据工程中的“特征提取”。
提取可交互元素：在Web自动化场景下，首先关注<a>, <button>, <input>等元素，这是最直接的思路，是标准做法。

**值得一提的部分：**
“意图映射”：声称能将模糊指令（“登录系统”）转换为具体的Playaright选择器操作，这个过程是真正有挑战性的。这背后通常需要一个语义搜索、分类或更复杂的Prompt Chain。如何实现从自然语言到具体UI元素引用的精确映射，而不是“我们没有把整个HTML都发给LLM”这件事本身。

2.2 关键代码引用

代码展示了如何整合页面上下文（URL、标题）与测试步骤描述，为LLM构建最小必要上下文。

code
TypeScript
download
content_copy
expand_less
// 文件: backend/src/services/ai/AiTestParser.ts

export class AITestParser {
  // ... (省略部分代码)
  
  async parseTestStep(
    stepDescription: string, // 用户输入的自然语言步骤
    pageSnapshot: string,    // 经过清洗的轻量级DOM快照
    currentUrl: string,      
    pageTitle: string
  ): Promise<{
    toolCalls: Array<{ name: string; arguments: any }>; // 解析出的标准化工具调用数组
    thoughtProcess: string; // 模型的思维链，用于调试
  }> {
    // ... (省略Prompt构建逻辑)
    
    // 调用LLM，要求其基于当前压缩后的快照解析用户意图
    const response = await this.llmProvider.generateCompletion(prompt);
    
    // ... (省略解析逻辑)
  }
}


**4. 基于MJPEG流的无头浏览器实时透传**
4.1 设计动因与解决的问题
Playwright在服务端以Headless模式运行，用户无法直观感知执行进度。WebRTC方案过于重型且需要复杂的ICE穿透配置。
决策逻辑： 采用MJPEG (Motion JPEG) 流技术。
**行业普遍实践部分：**
选择MJPEG：MJPEG over HTTP multipart response是一种非常古老、简单且广泛使用的视频流技术，常用于网络摄像头等场景。选择它而不是更复杂的WebRTC或WebSocket二进制流，是一个基于“简单、够用”原则的务实工程决策，但技术本身非常标准。
**值得一提的部分：**
与CDP事件流集成：亮点在于如何获取视频帧。直接挂钩到Playwright底层的CDP (Chrome DevTools Protocol) Page.screencastFrame事件流来获取屏幕帧，这表明开发者对Playwright工具有更深层次的理解

4.2 关键代码引用：建立HTTP响应流，并处理浏览器的 screencastFrame 事件，实现帧的实时转发。

code
TypeScript
download
content_copy
expand_less
// 文件: backend/src/services/stream/StreamService.ts

async startStream(res: Response, runId: string) {
    // 设置 MJPEG 标准响应头，告知浏览器这是一个持续更新的流
    res.writeHead(200, {
      "Content-Type": "multipart/x-mixed-replace; boundary=frame",
      "Cache-Control": "no-cache",
      Connection: "keep-alive",
    });

    // 获取对应的 CDP 会话
    const session = this.sessions.get(runId);
    
    // 监听 CDP 的截屏帧事件
    session.on("Page.screencastFrame", async ({ data, sessionId }) => {
      // 确认帧已接收，维持 CDP 会话活性
      await session.send("Page.screencastFrameAck", { sessionId });
      
      // 封装 JPEG 帧数据并写入 HTTP 响应流
      const frameData = Buffer.from(data, "base64");
      res.write(`--frame\r\nContent-Type: image/jpeg\r\nContent-Length: ${frameData.length}\r\n\r\n`);
      res.write(frameData);
      res.write("\r\n");
    });
}

**5. 具备并发熔断机制的任务队列管理**
5.1 设计动因与解决的问题

浏览器实例是内存密集型进程。若无限制地开启测试任务，会导致服务器OOM（内存溢出）宕机。简单的 Promise.all 无法控制最大并发数。
决策逻辑： 引入 p-queue 库构建优先级队列，并配合 Map 管理任务状态。
**行业普遍实践部分：**
控制资源密集型任务的并发：启动浏览器实例是典型的资源密集操作。如果不加控制地并发执行，服务器内存溢出是必然结果。因此，使用任务队列（如Bull, Celery, RabbitMQ）来管理任务并限制并发，是任何生产系统的基本要求。
使用p-queue等库：在Node.js环境中，使用p-queue或类似库来管理Promise的并发是标准实践，没人会手写一个任务调度器。
将并发数硬编码为1，这是一个极度保守的配置，确保了绝对的稳定性但牺牲了吞吐量。这是一个业务决策，而非技术亮点。做了最基本的服务器资源保护，是合格的后端开发者应该做的。这算不上亮点，而是避免了灾难。
状态一致性： 通过 activeRuns Map 追踪正在运行的任务，防止对已完成或已失败的任务进行重复操作。

**亮点：根据服务器负载动态调整并发数**
实现动态并发调整的难度不复杂，但在工程实践中有中等难度。主要挑战在于：
**定义“负载”：**你需要明确哪些指标（CPU、内存、事件循环延迟）能准确反映系统瓶颈。**确定阈值：**找到触发并发数增加或减少的合理阈值需要反复测试和调优。阈值过低会导致资源浪费，过高则可能导致系统不稳定。控制逻辑：实现一个稳定、无抖动的控制循环，避免因瞬时负载波动而频繁调整并发数。
具体陈述见下方 #### 根据服务器负载动态调整并发数

**6.  任务分解下的测试生成过程**
6.1 设计动因与解决的问题
直接要求LLM“生成测试用例”往往得到泛泛而谈的结果。复杂的业务逻辑需要分拆处理。
**行业普遍实践：**
任务分解（Decomposition）：将一个复杂的LLM任务（“生成测试用例”）分解为一系列更小、更简单的子任务（生成需求 -> 划分模块 -> 生成测试点），这是LLM Prompt工程中非常标准且有效的策略，通常被称为“Chain of Thought”或任务分解。
标准的Prompt工程：RequirementDoc -> TestModules -> TestPoints对业务领域的理解。

以下代码片段展示了第三阶段（测试点生成）如何依赖前序阶段的数据（模块列表）进行迭代生成。
// 文件: backend/src/services/ai/FunctionalTestCaseAIService.ts

async generateTestPoints(
    requirementDoc: string,
    modules: TestModule[] // 依赖上一阶段生成的模块列表
): Promise<TestPoint[]> {
    const allTestPoints: TestPoint[] = [];

    // 针对每个模块独立生成测试点，而非一次性生成所有
    // 这种策略降低了单次 LLM 请求的复杂度
    for (const module of modules) {
      const prompt = `
        Based on the requirements:
        ${requirementDoc}
        
        Generate test points for module: ${module.name}
        Description: ${module.description}
        ...
      `;
      // ... (调用 LLM 并累加结果)
    }
    return allTestPoints;
}

7. 基于JSON Patch (RFC 6902) 的原子化更新
7.1 设计动因与解决的问题
用户经常需要批量修改测试步骤。传统的全量覆盖更新（PUT）容易引发数据竞争，且难以追踪具体的修改项。此外，可以最小化传输： 前端只需发送操作指令（如 replace path="/steps/0/value"），而非整个对象，减少网络负载。

**行业普遍实践：**
在RESTful API中，使用PATCH方法进行资源的部分更新是一种标准。而JSON Patch (RFC 6902)是实现PATCH操作的官方标准化格式之一。选择它而不是发明自己的格式，是遵循行业标准的体现。使用成熟的库（如fast-json-patch）来处理这种标准格式也是常规操作。
代码展示了如何应用Patch操作到原始测试用例上，实现了非破坏性的更新。
// 文件: backend/src/services/ai/AiBulkUpdateService.ts

import * as jsonpatch from "fast-json-patch";

// ...

// 应用补丁：输入原始文档和 patch 操作数组，输出新文档
const newDocument = jsonpatch.applyPatch(
    originalDocument,
    patchOperations // 符合 RFC 6902 标准的操作数组
).newDocument;

// 这种方式使得更新操作是确定性的，并且可以通过 verifyPatch 预先检查合法性

**8. 测试制品持久化**
8.1 设计动因与解决的问题
测试执行不仅仅是Pass/Fail的结果，更重要的是可追溯的证据（截图、Trace文件）。这些二进制文件通常体积较大，不适合直接存入数据库。
决策逻辑： 实现 EvidenceService，分离元数据存储（DB）与大文件存储（文件系统/对象存储）。
**行业普遍实践：**
分离元数据和二进制文件：将大文件（图片、视频、zip包）存储在文件系统或对象存储（如S3）中，而在数据库中只存储其元数据（路径、ID、时间戳等），这是应用架构设计的基本原则。直接将二进制大对象（BLOB）存入关系型数据库是公认的反模式。
**值得一提的部分：**
保存Playwright Trace（.zip）文件：这个决策本身是亮点。它表明开发者不仅仅满足于“测试通过/失败”，而是深入利用了Playwright的调试能力，允许开发者在本地以时间轴方式完全重放测试执行过程，复现Flaky Tests。

代码引用：文件路径的规范化处理以及 Trace 文件的保存逻辑。

// 文件: backend/src/services/evidence/EvidenceService.ts

// 构建基于 runId 的隔离存储目录
const evidenceDir = path.join(process.cwd(), "evidence", runId);

// ...

// 保存 Trace 文件
// Playwright 上下文追踪停止时导出 trace 包
await context.tracing.stop({
    path: path.join(evidenceDir, "trace.zip"),
});

// 记录元数据到内存或数据库，指向物理文件路径
this.evidenceStore.set(runId, {
    screenshots: screenshotPaths,
    tracePath: `/evidence/${runId}/trace.zip`, // 相对路径，用于前端访问
    logs: logs,
});

**9. 多租户架构下的知识库隔离**
9.1 设计动因与解决的问题
在SaaS模式或多项目环境中，AI很容易混淆不同项目的业务规则。如果不仅行物理或逻辑隔离，AI可能会用A项目的登录账号去测试B项目。
决策逻辑： 在 TestCaseKnowledgeBase 中强制实施基于 systemName 的命名空间策略。索引级隔离： 在创建向量集合（Collection）时或查询时，始终携带系统标识。相关性提升： 缩小了向量检索的搜索空间（Search Space），使得召回的上下文不仅语义相关，而且业务域正确。

**行业普遍实践：**
使用元数据过滤实现数据隔离：在向量数据库中，通过在Payload/Metadata中存储systemName等字段，并在检索时使用filter参数，是实现多租户或多项目数据隔离的标准且唯一推荐的方法。未展示任何超出标准实践的创新。

代码显示了在添加文档到知识库时，如何构建包含系统标识的Payload，为后续的过滤查询打下基础。
// 文件: backend/src/services/knowledgeBase/TestCaseKnowledgeBase.ts

async addTestCase(
    testCase: string,
    category: string,
    systemName: string // 关键参数：系统标识
): Promise<void> {
    // ...
    await this.client.upsert(this.collectionName, {
      points: [
        {
          id: uuidv4(),
          vector: embedding,
          payload: {
            content: testCase,
            category,
            system: systemName, // 将系统名固化到向量 Payload 中
            timestamp: Date.now(),
          },
        },
      ],
    });
}
**10. 事件驱动的实时状态同步 (WebSocket)**
10.1 设计动因与解决的问题
HTTP轮询（Polling）状态（如“测试中”、“已完成”）会造成不必要的网络开销和数据库压力，且延迟较高。
决策逻辑： 集成 socket.io 实现全双工通信。 测试执行的每一个步骤（启动、步骤成功、步骤失败、结束）都作为事件实时推送到前端，用户感知无延迟。支持多用户协同，一个用户触发测试，其他查看同一页面的用户也能实时看到状态变化。

**行业普遍实践：**
当需要服务器向客户端实时推送信息时，替代方案是HTTP轮询、长轮询、服务器发送事件（SSE）和WebSocket。对于需要低延迟、双向通信的场景，WebSocket是标准的、主流的技术选型。
一个健壮的WebSocket实现（包括心跳、自动重连、按runId分发消息的“房间”或“频道”机制）是值得一提的。代码片段中只展示了一个简单的全局广播（this.io.emit），这是最基础的用法。如果实现了更复杂的频道管理，那才是亮点。

代码展示了WebSocket服务的单例封装及状态广播方法的实现。

code
TypeScript
download
content_copy
expand_less
// 文件: backend/src/services/websocket/WebSocketService.ts

broadcastStatus(runId: string, status: any) {
    // 向所有连接的客户端广播特定 runId 的状态更新事件
    // 前端监听 'executionStatus' 事件即可实现进度条或状态图标的实时刷新
    this.io.emit("executionStatus", {
      runId,
      ...status,
      timestamp: Date.now(),
    });
}

#### 根据服务器负载动态调整并发数

如果要包装，可以包装为：. **智能并发控制**：基于系统资源动态调整任务并发数，防止单个用户占用过多资源， **熔断和恢复机制**：在资源紧张时自动降级，资源恢复后自动扩容
事实： 将 p-queue 配合简单的 if/else 阈值判断称为“具备并发熔断机制的任务队列管理”略显夸张。“熔断（Circuit Breaker）”通常指遇到错误率升高时切断流量，而这里是基于资源的“流控（Throttling）”或“自适应并发（Adaptive Concurrency）”。
TypeScript 只是静态类型检查器，运行时是 Node.js (C++ binding)。准确的描述应为“利用 Node.js 运行时 API 实现的资源监控。

限制：专为本地开发环境（单机）设计，不依赖 Docker/K8s，但能有效防止系统因浏览器实例过多而崩溃。

1.1 设计动因
在本地开发机或单体服务器上运行浏览器自动化任务（如 Playwright/Puppeteer）时，瓶颈通常不在 Node.js 进程本身，而在操作系统层面的物理内存（RAM）和CPU总负载。
**目标系统行为：**
低负载时：当服务器空闲时，系统会自动增加并发数（例如，从1增加到4）。用户提交的多个测试任务将并行执行，显著缩短总体等待时间。例如，4个耗时1分钟的任务，理想情况下总耗时约1分钟，而不是4分钟。
高负载时：当CPU或内存使用率超过设定的高阈值（例如80%）时，系统会自动减少并发数，甚至降至1。这会减慢新任务的处理速度，但可以防止服务器因资源耗尽而崩溃，起到“熔断”作用。
负载恢复后：当负载降至低阈值以下，系统会再次逐步增加并发数，恢复吞吐能力。

**监控什么指标？**
**内存（Memory）：** 浏览器是典型的内存吞吐型应用。每个 Tab 页可能消耗 100MB-1GB 不等。一旦物理内存耗尽，操作系统会进行页交换（Swap），导致系统假死，或者直接触发 OOM Killer 杀掉进程。这是硬指标，必须作为熔断的最高优先级。
**CPU（Load Average）：** 多个浏览器实例同时渲染、执行 JS 会打满 CPU 核心。使用 os.loadavg() 可以获取系统在过去 1 分钟的平均活跃进程数。对于本地开发机（通常为 4-8 核），此指标能反映整体拥堵程度。
**事件循环延迟（Event Loop Lag）：** 即使系统资源充足，如果 Node.js 主线程被大量的同步代码阻塞（例如处理大量 JSON 或复杂的调度逻辑），也无法及时响应新的 I/O。这是**Node.js 自身的健康指标**

**1.2 控制逻辑：带冷却的负反馈循环**
为了防止并发数在临界值附近剧烈抖动（例如：内存刚好在 80% 上下波动，导致并发数频繁 +1/-1），我们引入冷却机制（Cooldown）和滞后区间（Hysteresis）。
降级逻辑（熔断）： 只要满足 任意 一个危险指标（内存过低 OR CPU过载 OR 主线程卡顿），立即减少并发。安全第一。
升级逻辑（恢复）： 必须 同时 满足所有安全指标（内存充裕 AND CPU空闲 AND 主线程流畅），且距离上次调整已过去一定时间（冷却期），才允许增加并发。

代码实现：新增/修改三个文件。

文件 1：资源监控模块
路径： src/lib/monitoring/SystemMonitor.ts 功能： 纯粹的数据获取，不包含业务逻辑。封装 Node.js 原生 os 模块和 perf_hooks。

import os from 'os';
import { monitorEventLoopDelay } from 'perf_hooks';

export interface SystemMetrics {
  freeMemPercentage: number; // 0-100: 剩余物理内存百分比
  cpuLoadRatio: number;      // 0-1+: 系统负载除以CPU核心数 (1.0代表满载)
  eventLoopLag: number;      // ms: 事件循环延迟
}

export class SystemMonitor {
  private histogram: ReturnType<typeof monitorEventLoopDelay>;

  constructor() {
    // 启用事件循环延迟采样，分辨率为 10ms
    this.histogram = monitorEventLoopDelay({ resolution: 10 });
    this.histogram.enable();
  }

  public getMetrics(): SystemMetrics {
    // 1. 内存监控 (物理内存)
    const totalMem = os.totalmem();
    const freeMem = os.freemem();
    const freeMemPercentage = (freeMem / totalMem) * 100;

    // 2. CPU 监控 (系统平均负载 - 1分钟平均值)
    // 注意：Windows下 os.loadavg() 可能始终返回 [0,0,0]，需做兼容处理
    // 在 Windows 上，如果没有可靠的 loadavg，我们主要依赖内存和Lag
    const cpus = os.cpus().length;
    const loadAvg = os.loadavg()[0]; 
    const cpuLoadRatio = loadAvg / cpus;

    // 3. Event Loop Lag (主线程阻塞程度)
    // 获取 99 分位数的延迟，比平均值更敏感，能捕捉偶发的卡顿
    const eventLoopLag = this.histogram.percentile(99) / 1e6; // 纳秒转毫秒

    return {
      freeMemPercentage,
      cpuLoadRatio,
      eventLoopLag
    };
  }

  // 重置直方图，防止历史数据影响当前判断
  public resetLagMonitor() {
    this.histogram.reset();
  }
}
文件 2：动态并发控制器
路径： src/lib/queue/ConcurrencyController.ts 功能： 决策。持有状态，决定并发数是升还是降。

import { SystemMonitor, SystemMetrics } from '../monitoring/SystemMonitor';

interface ControllerConfig {
  minConcurrency: number;
  maxConcurrency: number;
  // 阈值设置
  memDangerThreshold: number; // 比如 10% (剩余内存低于此值极度危险)
  memSafeThreshold: number;   // 比如 30% (剩余内存高于此值才考虑加并发)
  cpuDangerRatio: number;     // 比如 1.0 (CPU满载)
  cpuSafeRatio: number;       // 比如 0.7 (CPU有余量)
  lagThreshold: number;       // 比如 50ms
  // 冷却时间 (ms)
  cooldownMs: number;
}

export class ConcurrencyController {
  private monitor: SystemMonitor;
  private config: ControllerConfig;
  
  private currentConcurrency: number;
  private lastAdjustmentTime: number = 0;

  constructor(options: Partial<ControllerConfig> = {}) {
    this.monitor = new SystemMonitor();
    this.config = {
      minConcurrency: 1,
      maxConcurrency: 5, // 本地开发机建议设置保守点，比如 CPU 核心数 - 1
      memDangerThreshold: 15, // 剩余内存低于 15% 报警
      memSafeThreshold: 40,   // 剩余内存高于 40% 才敢加量
      cpuDangerRatio: 0.9,
      cpuSafeRatio: 0.6,
      lagThreshold: 100,
      cooldownMs: 5000, // 5秒冷却，防止抖动
      ...options
    };
    this.currentConcurrency = this.config.minConcurrency;
  }

  public getNextConcurrency(): number {
    const now = Date.now();
    const metrics = this.monitor.getMetrics();
    
    // 打印实时指标，用于本地调试观察 (生产环境可降级为 debug)
    console.log(`[Monitor] MemFree: ${metrics.freeMemPercentage.toFixed(1)}% | CPU LoadRatio: ${metrics.cpuLoadRatio.toFixed(2)} | Lag: ${metrics.eventLoopLag.toFixed(0)}ms | Cur: ${this.currentConcurrency}`);

    // 1. 熔断检查 (优先级最高，无视冷却时间，立即降级)
    // 如果内存极低，必须立即释放压力，防止系统死机
    if (metrics.freeMemPercentage < this.config.memDangerThreshold) {
      console.warn(`[Controller] ⚠️ Memory critical (${metrics.freeMemPercentage.toFixed(1)}% < ${this.config.memDangerThreshold}%). Emergency scale down.`);
      // 内存危急时，直接降到最小值
      this.currentConcurrency = this.config.minConcurrency;
      this.lastAdjustmentTime = now;
      return this.currentConcurrency;
    }

    // 2. 冷却期检查
    if (now - this.lastAdjustmentTime < this.config.cooldownMs) {
      return this.currentConcurrency;
    }

    // 3. 降级逻辑 (常规过载)
    const isOverloaded = 
      metrics.cpuLoadRatio > this.config.cpuDangerRatio || 
      metrics.eventLoopLag > this.config.lagThreshold;

    if (isOverloaded) {
      if (this.currentConcurrency > this.config.minConcurrency) {
        this.currentConcurrency--;
        this.lastAdjustmentTime = now;
        console.log(`[Controller] 📉 Load high. Decreasing concurrency to ${this.currentConcurrency}`);
      }
      return this.currentConcurrency;
    }

    // 4. 升级逻辑 (资源充裕)
    const isSafeToGrow = 
      metrics.freeMemPercentage > this.config.memSafeThreshold && 
      metrics.cpuLoadRatio < this.config.cpuSafeRatio && 
      metrics.eventLoopLag < 10; // 只有系统非常流畅时才加

    if (isSafeToGrow) {
      if (this.currentConcurrency < this.config.maxConcurrency) {
        this.currentConcurrency++;
        this.lastAdjustmentTime = now;
        console.log(`[Controller] 📈 Resources available. Increasing concurrency to ${this.currentConcurrency}`);
      }
    }

    return this.currentConcurrency;
  }
}
文件 3：集成到任务队列
路径： src/worker.ts (或其他你初始化 p-queue 的地方) 功能： 将控制器与 p-queue 绑定。

import PQueue from 'p-queue';
import { ConcurrencyController } from './lib/queue/ConcurrencyController';

// 1. 初始化控制器
const controller = new ConcurrencyController({
  maxConcurrency: 4, // 根据你本地机器配置设定，建议 8G内存设为2-3，16G内存设为4-6
  minConcurrency: 1,
  cooldownMs: 3000
});

// 2. 初始化队列
const queue = new PQueue({ 
  concurrency: 1, // 初始并发
  autoStart: true 
});

// 3. 核心：在任务完成/分发时调整并发
// 我们不使用 setInterval 轮询，而是在队列状态变化时触发检查，这样更高效
const adjustQueue = () => {
  const nextLimit = controller.getNextConcurrency();
  if (queue.concurrency !== nextLimit) {
    queue.concurrency = nextLimit;
  }
};

// 模拟一个耗时的浏览器任务
const runBrowserTask = async (id: number) => {
  console.log(`Task ${id} started`);
  // 模拟资源消耗：这里应当是你真实的 Playwright 代码
  // await page.goto(...);
  await new Promise(resolve => setTimeout(resolve, 2000 + Math.random() * 3000));
  console.log(`Task ${id} finished`);
};

// 4. 任务添加与事件监听
export const startWorker = async () => {
  // 监听 'active' 事件：每当有任务开始执行，检查是否要降级
  queue.on('active', () => {
    // 注意：过于频繁的检查可能会有性能损耗，这里依赖 Controller 内部的 cooldown 控制
    adjustQueue();
  });

  // 监听 'next' 事件：每当有任务完成，检查是否要升级
  queue.on('next', () => {
    adjustQueue();
  });

  // 模拟批量添加任务
  for (let i = 0; i < 50; i++) {
    queue.add(() => runBrowserTask(i));
  }
  
  await queue.onIdle();
  console.log('All tasks finished');
};

**验证过程（本地开发者视角）**

问题：当多个用户同时提交测试请求时，系统能否智能地调节并发数以防止资源耗尽？如何在不使用复杂压力测试工具的情况下，验证这套机制在你的笔记本电脑上是有效的？

建立基准（Baseline）：打开你的任务管理器（Windows Task Manager）或活动监视器（macOS Activity Monitor）。找到 "Node" 进程和 "Memory"（内存）列。运行上面的代码，但将 maxConcurrency 锁定为 1。录下运行单个浏览器任务时，你的系统剩余内存大概是多少？Node.js 打印的 logs 中 CPU LoadRatio 是多少？

注意，memDangerThreshold 是我们代码中的逻辑判定值。ControllerConfig 接口中定义的一个配置参数（即：人为设定的报警线），
  // 配置常量（生产环境建议值）
  private readonly CONFIG = {
    MIN_CONCURRENCY: 1,
    MAX_CONCURRENCY: 10,         // 允许尝试冲高
    MEM_DANGER_THRESHOLD: 20,    // [硬指标] 剩余内存低于 20% 必须熔断
    MEM_SAFE_THRESHOLD: 40,      // 剩余内存高于 40% 才允许扩张
    COOLDOWN_MS: 2000            // 冷却时间
  };

设计思路： 我们需要在 Node.js 内部模拟浏览器的资源消耗行为。既然不能依赖真实的浏览器，我们用 Buffer 模拟内存占用，用空转循环模拟 CPU 占用。

这个脚本将执行以下操作：
数据记录： 每 200ms 将系统指标（内存、并发数）写入 test_report.csv，以便用 Excel 生成图表。压力注入： 任务队列会不断执行“重型模拟任务”。观察 CSV 数据，证明当内存下降时，并发数自动下降。

// StressTest.ts
import PQueue from 'p-queue';
import * as fs from 'fs';
import * as os from 'os';
import { ConcurrencyController } from './ConcurrencyController';

// 1. 定义一个模拟的重型任务 (模拟浏览器实例)
// 特点：占用大量内存 (200MB)，占用一定 CPU，持续 3 秒
const simulateBrowserTask = async (taskId: number) => {
  // A. 模拟内存分配 (Buffer 是堆外内存，直接消耗 OS 物理内存，模拟 Chromium 渲染进程)
  const memoryHog = Buffer.alloc(1024 * 1024 * 200); // 分配 200MB
  
  // B. 填充数据以确保内存被实际提交 (防止 OS 惰性分配)
  memoryHog.fill(1); 

  // C. 模拟 CPU 计算 (阻塞 100ms)
  const start = Date.now();
  while (Date.now() - start < 100) { Math.random(); }

  // D. 保持任务运行一段时间
  await new Promise(resolve => setTimeout(resolve, 3000));

  // E. 释放引用 (模拟页面关闭)
  // void memoryHog; // 实际由 GC 回收
};

const runTest = async () => {
  const controller = new ConcurrencyController();
  const queue = new PQueue({ concurrency: 1 });
  
  // 初始化 CSV 日志文件
  const logStream = fs.createWriteStream('test_report.csv');
  logStream.write('Time(ms),FreeMem(%),Concurrency,QueueSize\n');

  const startTime = Date.now();

  // 2. 启动监控循环 (每 200ms 采样一次)
  const monitorInterval = setInterval(() => {
    const now = Date.now() - startTime;
    const totalMem = os.totalmem();
    const freeMem = os.freemem();
    const freePercent = (freeMem / totalMem) * 100;
    
    // 核心：根据控制器调整队列并发
    const newConcurrency = controller.adjust();
    if (queue.concurrency !== newConcurrency) {
      queue.concurrency = newConcurrency;
    }

    // 写入数据
    logStream.write(`${now},${freePercent.toFixed(2)},${queue.concurrency},${queue.size}\n`);

    // 打印到控制台以便实时观察
    process.stdout.write(`\r[Time: ${now}ms] FreeMem: ${freePercent.toFixed(1)}% | Concurrency: ${queue.concurrency} | Pending: ${queue.size}   `);

    // 停止条件：运行 30 秒后停止
    if (now > 30000) {
      clearInterval(monitorInterval);
      logStream.end();
      console.log('\n\nTest finished. Check test_report.csv');
      process.exit(0);
    }
  }, 200);

  // 3. 持续向队列加压 (模拟并发请求洪峰)
  console.log('Starting Stress Test...');
  let taskId = 0;
  
  // 每 100ms 塞入一个新任务，制造积压
  setInterval(() => {
    queue.add(() => simulateBrowserTask(taskId++));
  }, 100);
};

runTest();

**验证过程与预期指标分析**
在本地终端运行 ts-node StressTest.ts，30 秒后打开生成的 test_report.csv，关注三个阶段的数据变化：

阶段 1：爬坡期 (0s - 5s)
行为： 脚本刚启动，内存充裕（例如 60% 空闲）。
CSV 数据预期：
FreeMem: 缓慢下降（随着任务开始执行，Buffer 被分配）。
Concurrency: 阶梯状上升 (1 -> 2 -> 3...)。这是因为控制器判断内存 > 40% (MEM_SAFE_THRESHOLD)，允许扩张。
QueueSize: 增加，因为任务产生速度 (10/s) 快于处理速度。

阶段 2：临界/熔断期 (5s - 15s)
行为： 并发数达到较高值（例如 8），此时同时运行 8 个任务，消耗约 1.6GB 内存。系统剩余内存逼近 20% (MEM_DANGER_THRESHOLD)。

CSV 数据预期：
FreeMem: 跌破 20%。
Concurrency: 瞬间断崖式下跌 (例如从 8 直接变回 1)。
证明： 这证明了硬熔断机制生效。控制器通过强制减少并发，阻止了更多任务同时运行，防止内存彻底耗尽（OOM）。

阶段 3：恢复期 (15s - 30s)
行为： 由于并发降为 1，旧任务陆续完成释放内存，新任务排队等待。
CSV 数据预期：
FreeMem: 开始回升（Buffer 被 GC 回收）。
Concurrency: 保持在 1 一段时间（冷却期），然后随着内存回升到 40% 以上，再次缓慢尝试增加。
证明： 这证明了系统自愈。

不依赖视频播放等不可控的外部干扰，而是通过代码 (Buffer.alloc) 产生精确的、对操作系统可见的内存压力。如果 FreeMem 曲线向下穿过 20% 线的那一刻，Concurrency 曲线没有立刻垂直向下，则证明设计失败。







问题1：如何用原生代码监控CPU、内存和事件循环延迟？

**不应该使用的错误计算方式**

process.cpuUsage() 和 process.memoryUsage() 仅能监控 Node.js 主进程本身的资源消耗。`process.cpuUsage()` 获取Node.js进程的用户和系统CPU时间消耗（微秒），然后除以实际经过的时间，再除以CPU核心数，得到一个0到1之间的进程CPU使用率。`process.memoryUsage()` 获取V8引擎的堆内存使用情况（`heapUsed`）和进程的总常驻内存（`rss`）。`rss` 是一个更全面的指标，因为它包含了C++对象和外部绑定的内存。

错在哪里？Playwright 或 Puppeteer 启动的浏览器实例（Chromium/Firefox）是作为子进程（Child Processes） 运行的，独立于 Node.js 主进程之外。Node.js 主进程只负责发送指令（如“点击按钮”），CPU 消耗极低。真正的 CPU 消耗大户是渲染页面的 Chromium 进程。您的 getProcessCpuUsage 读出的数值可能只有 1%，而此时机器的 Chromium 进程可能已经把 CPU 跑满到了 100%。同理，process.memoryUsage() 返回的是 Node.js 堆内存（Heap）。Chromium 的渲染内存（Render Process Memory）并不包含在其中。

后果： 监控指标与实际负载完全脱节。Node.js 认为系统很空闲（因为它自己没干活），于是 DynamicConcurrencyManager 会不断增加并发，直到无数个 Chromium 子进程瞬间耗尽服务器内存，导致宕机。必须放弃 process.cpuUsage()，改回使用操作系统级别的监控 os.loadavg() 和 os.freemem()，或者使用 pidusage 库来聚合计算所有子进程的资源消耗。
