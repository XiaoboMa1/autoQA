议会质询报告

致使用者：

已收到你的质询。此报告将直接回应你提出的四个核心问题。报告遵循信息传递的精确性与严谨性原则，不包含任何非必要的情感化或修饰性语言。

问题【1】：关于原型图用途的质疑

你的前提是正确的：在传统工作流中，Axure原型图的核心功能是视觉与交互设计展示，而非作为测试用例设计的直接输入。

本系统的核心假设是：一个足够详尽、遵循特定规范的Axure原型，其静态HTML产物包含了可被机器解析的、结构化的需求信息。系统并非将原型图作为交互模型来“运行”，而是将其作为一份机器可读的需求文档来“解析”。

工作机制如下：

输入: 系统接收的是Axure导出的HTML、CSS和JS文件集合，而非.rp源文件或图片。

解析: 后端服务（axureParseService.ts）使用DOM解析库（如cheerio）遍历HTML结构。它不关心页面的视觉表现，只提取结构化信息：元素类型（通过class和tag推断）、标签文本、元素ID、data-label等Axure特有的属性。

转换: 解析后的DOM结构被转换成一份结构化的JSON对象。这份JSON对象是对页面元素的“盘点清单”，例如：{ "type": "input", "name": "用户名" }, { "type": "button", "text": "登录" }。

推断: 这份JSON清单随后被提交给大语言模型（LLM），LLM的任务是基于这份清单“逆向工程”出一份产品需求文档（PRD）。

结论: 系统并未改变原型图用于“设计展示”的本质。它只是利用了Axure导出产物的结构化特性，将其作为一种替代性的、不规范但可解析的需求规约来源。其有效性完全依赖于原型制作的规范性和详尽程度。

问题【2】：关于数据库结构的强制性

是的，报告中涉及的数据库表结构是强制性的，缺少这些表，相关功能将完全无法运行。系统的数据持久化、版本控制和AI生成流程都依赖于此结构。

核心新增表结构解析：

ai_generation_sessions:

用途: 记录每一次从“上传Axure”到“生成用例”的完整会话。

关键字段: id (会话ID), user_id, axure_filename, requirement_doc (AI生成的需求文档), pre_analysis_result (智能补全分析结果), enhanced_data (用户确认后的数据)。

必要性: 确保所有AI生成过程可追溯、可审计。没有此表，无法在多步骤流程中传递上下文。

functional_test_cases:

用途: 存储高级别的测试用例，对应“测试目的”。它是一个容器。

关键字段: id, name, system, module, ai_session_id (关联生成会话)。

必要性: 组织和管理测试点，形成测试用例的层级结构。

functional_test_points:

用途: 存储具体的、可执行的测试点，是测试用例的最小单元。

关键字段: id, test_case_id (关联functional_test_cases), test_point_name, steps, expected_result, risk_level。

必要性: 这是最终产物的核心存储单元。一个functional_test_case包含多个functional_test_points。

关于向量数据库 (Qdrant):

用途: 此数据库用于实现RAG（检索增强生成）功能，是系统的增强层而非核心层。

工作机制: 它将业务规则、历史缺陷（pitfall）、风险场景等知识条目，通过Embedding模型（如阿里云通义）转换为向量并存储。在生成测试点时，系统会根据当前上下文在向量数据库中进行语义搜索，找到最相关的知识，并将其注入到LLM的提示词中，以生成更专业、更具针对性的测试点。

必要性: 如果不部署Qdrant或相关配置，系统仍然可以生成测试用例，但质量会显著下降，无法利用历史经验，也无法自动生成边界、异常和风险场景的测试。它将退化为一个纯粹基于原型内容推断的生成器。

问题【3】：“成熟原型”与“任意HTML”的界定

你的理解是正确的，系统接收的是HTML输入。然而，“理论上可以把任何HTML丢进去”这一推论是不成立的。

原因如下：

解析器高度耦合: axureParseService.ts中的解析逻辑是为Axure导出的特定HTML结构量身定制的。它依赖于Axure生成的特定class名称、ID格式和data-*属性。

示例: 系统通过查找div.ax_default.label来识别按钮和标签，并通过文本长度和关键词来区分两者。一个标准的网页（如<div><button>提交</button></div>）不包含这种结构，会导致按钮识别失败。

结构化假设: 系统假设HTML内容在结构上反映了功能的组织。例如，它会假定“查询”按钮附近的输入框是查询条件，而“保存”按钮附近的输入框是表单字段。普通网页的布局可能不遵循这种简单的逻辑。

“成熟原型”的定义: 在此项目的语境下，“成熟”指的不是原型在设计评审流程中的状态，而是其内容的详尽和规范程度。一个“成熟”的Axure原型意味着：

所有可交互元素（按钮、输入框）都已绘制。

所有元素的标签文本都已正确填写。

页面之间的跳转关系已通过交互链接建立。

复杂的业务规则已通过注释或文本块的形式在原型中说明。

结论: 将任意网站的HTML输入此系统，解析器会因找不到预期的结构模式而失败，或提取出大量无意义的、非结构化的元素，导致后续AI生成的需求文档质量极低或完全不可用。该系统对输入源的格式有强依赖性，并不具备通用HTML页面的解析能力。

问题【4】: 系统完整工作流程详解

以下为系统从接收用户上传到最终保存测试用例的完整、详细步骤分解。

步骤 1.1: 用户上传与信息补充

输入: 用户在前端页面 (/functional-test-cases/generator) 上传一个或多个文件（必须包含至少一个.html文件），这些文件是Axure导出的产物。同时，用户输入系统名称、模块名称，并可选填写补充业务规则。

数据示例:

文件: 订单管理.html, data.js

系统名称: 电商后台

模块名称: 订单管理

补充规则: 订单金额超过10000元需要财务审批

步骤 1.2: 后端文件解析 (axureParseService.ts)

过程: 后端接收到文件后，首先识别出主HTML文件。随后，使用DOM解析库（cheerio）遍历HTML的树状结构。

提取逻辑:

元素识别: 查找带有Axure特定class（如 ax_default label, ax_default text_field）或tag（input, select）的元素。

文本提取: 提取元素的可见文本，如按钮名“查询”、输入框标签“订单号”。

类型推断: 根据元素的class、tag和文本内容，将其初步分类为 button, input, select, div 等。

业务规则提取: 专门查找长文本块（div），特别是包含“规则”、“说明”、“备注”或特定关键词（审核、校验、拦截）的文本，作为业务规则的原始素材。

输出: 一个结构化的JSON对象，包含了页面上所有被识别的元素及其属性。

数据示例:

HTML片段: <div id="u123" class="ax_default label"><div class...><p><span>查询</span></p>...</div>

解析结果 (JSON片段): { "id": "u123", "type": "button", "text": "查询" }

步骤 1.3: AI生成需求文档初稿 (functionalTestCaseAIService.ts)

过程: 将步骤1.2中生成的JSON对象、用户输入的项目信息、以及HTML文件中的长文本规则，全部打包成一个巨大的提示词（Prompt）发送给大语言模型（LLM）。

AI任务: 提示词指示AI扮演一名“需求分析专家”，其任务是：

理解页面类型: 根据元素组合（如：有“查询”按钮和表格 -> 列表页；有“保存”按钮和输入框 -> 表单页）判断页面类型。

功能模块化: 将离散的元素（输入框、按钮）组合成有业务意义的功能模块（如“查询条件区”、“操作按钮区”）。

结构化输出: 按照预设的Markdown模板，生成包含页面布局、查询条件、列表字段、操作按钮、业务规则等章节的需求文档（PRD）。

输出: 一份Markdown格式的文本。

数据示例:

输入 (JSON片段): [{ "type": "input", "name": "订单号" }, { "type": "button", "text": "查询" }]

输出 (Markdown片段):

code
Markdown
download
content_copy
expand_less
#### 1.1.2 查询条件
| 字段名 | 控件类型 | 必填 |
|---|---|---|
| 订单号 | 文本框 | 否 |

步骤 1.4: 用户审核需求文档 (第一个关键节点)

过程: 后端将生成的Markdown文档返回给前端，前端使用编辑器（MarkdownEditor.tsx）将其展示给用户。

用户操作: 用户可以阅读、编辑、补充或修正这份AI生成的需求文档。例如，补充AI未能推断出的隐藏业务规则，或修正AI对字段的错误理解。

输出: 一份经过用户确认和优化的最终版需求文档。这份文档是后续所有生成步骤的唯一依据。

步骤 2.1: 阶段一 - AI拆分测试模块

输入: 用户审核过的最终版需求文档。

过程: 用户点击“生成测试用例”后，前端将需求文档全文提交给后端。后端再次调用LLM。

AI任务: 提示词指示AI扮演一名“测试架构师”，将需求文档按功能或章节拆分为高级别的测试模块。

输出: 一个测试模块列表。

数据示例:

输入: 包含“查询条件”、“列表展示”、“操作按钮”等章节的需求文档。

输出 (JSON): [{ "id": "module-1", "name": "查询条件测试" }, { "id": "module-2", "name": "列表数据与操作测试" }]

步骤 2.2: 阶段二 - AI生成测试目的

输入: 用户从模块列表中选择一个或多个模块。

过程: 对于用户选择的每个模块，后端再次调用LLM，并将该模块关联的需求文档内容一并传入。

AI任务: 提示词指示AI扮演一名“高级测试工程师”，为指定的测试模块设计更高层级的测试目的（Test Purpose）。

输出: 每个模块下生成2-8个测试目的。

数据示例:

输入: “查询条件测试”模块。

输出 (JSON): [{ "id": "purpose-1", "name": "单条件查询验证" }, { "id": "purpose-2", "name": "多条件组合查询验证" }, { "id": "purpose-3", "name": "边界值与异常输入测试" }]

步骤 2.3: 阶段三 - AI生成测试点 (RAG增强)

这是整个系统技术含金量最高的一步。

输入: 用户从测试目的列表中选择一个或多个目的。

过程: 对于用户选择的每个测试目的，后端执行以下RAG流程：

构建查询: 将测试目的的名称和描述（如“边界值与异常输入测试”）以及相关的需求文档片段组合成一个语义查询。

向量化: 调用Embedding模型（如阿里云通义）将该查询文本转换为一个1024维的向量。

语义检索 (testCaseKnowledgeBase.ts): 使用此向量在Qdrant向量数据库的对应系统集合（test_knowledge_{系统名称}）中进行相似度搜索。

知识获取: Qdrant返回最相似的知识条目，例如，对于“边界值测试”，可能会检索到：

历史踩坑点: “特殊字符 " 和 ' 未转义导致查询失败”

风险场景: “SQL注入风险：输入 ' OR '1'='1 验证”

业务规则: “订单号长度必须为18位”

上下文增强: 将这些检索到的知识条目格式化后，注入到一个新的、最终的LLM提示词中。

最终生成调用: 将测试目的、相关需求文档内容、以及增强的知识上下文，一同发送给LLM。

AI任务: 提示词指示AI扮演一名“资深测试专家”，基于所有上下文，生成具体的、包含操作步骤、预期结果和风险等级的测试点（Test Point）。

输出: 一个包含多个测试点的完整测试用例JSON对象。

数据示例:

输入: “边界值与异常输入测试” + RAG检索到的知识。

输出 (JSON片段):

code
JSON
download
content_copy
expand_less
{
  "testPointName": "SQL注入风险测试",
  "steps": "1. 在订单号输入框输入 ' OR '1'='1\n2. 点击查询按钮",
  "expectedResult": "系统应提示查询无结果或参数无效，不应返回所有数据或报错",
  "riskLevel": "high"
}

步骤 3.1: 草稿箱展示与审核 (最后一个关键节点)

过程: 后端将生成的测试用例（包含多个测试点）返回给前端。前端以卡片形式在“草稿箱”中展示每个测试用例。

用户操作:

预览: 用户可以点击查看每个测试用例的详细测试点。

编辑: 用户可以在弹窗中直接修改测试点的步骤、预期结果等。

选择: 用户通过复选框选择最终需要保存的测试用例。

步骤 3.2: 保存到数据库

过程: 用户点击“保存到用例库”后，前端将所有选中的测试用例JSON对象批量提交给后端。

后端操作:

启动一个数据库事务。

为每个提交的测试用例，在 functional_test_cases 表中创建一条主记录。

对于该用例下的每个测试点，在 functional_test_points 表中创建一条记录，并关联到主记录的ID。

事务提交。

输出: 数据被持久化到MySQL数据库中，流程结束。用户被重定向到功能测试用例列表页面，可以看到刚刚保存的所有用例和测试点。


议会质询报告

致使用者：

已收到你的质询。此报告将直接回应你提出的核心问题，并基于提供的系统文件进行事实陈述。

1. 关于系统定位：“它是一个工作台吗？”

肯定回答：是。

它的定位是一个专用于测试用例设计与生成阶段的辅助工具集，即一个“工作台”（Workbench）。它并非一个全面的、端到端的测试管理平台（如Jira+Xray, TestRail），因为它不直接处理测试执行跟踪、缺陷管理或测试报告的完整生命周期。

其核心功能限定在以下范围内：

原型解析: 将Axure原型HTML作为结构化数据源进行解析。

需求生成: 基于解析结果，利用LLM生成一份可读的需求文档初稿。

用例生成: 基于需求文档，通过三阶段渐进式流程生成测试模块、测试目的和具体的测试点。

草稿审核: 提供一个临时工作区（草稿箱）供用户审核、编辑和选择生成的用例。

2. 关于“草稿箱”的位置与性质

“草稿箱”不是一个持久化的、独立的功能模块，而是在“AI生成器”页面 (/functional-test-cases/generator) 的第三个步骤（生成用例）中，用于临时展示和管理AI生成结果的前端状态容器。

具体特征：

位置: 它仅存在于AI生成器页面的第三步界面中。

临时性: 其内容存储在前端应用的内存状态（React State）中，并可能缓存到浏览器的LocalStorage以防止意外关闭。这些数据在用户点击“保存到用例库”或离开页面后即被清空或失效。

交互性: 用户在此区域内对AI生成的测试用例卡片进行交互，包括：

通过复选框选择或取消选择。

点击卡片打开详情弹窗（TestCaseDetailModal.tsx）进行编辑。

触发“重新生成”、“优化”等批量操作。

目的: 它的唯一目的是作为将AI生成结果持久化到数据库（functional_test_cases 和 functional_test_points 表）之前的缓冲区和审核区。

3. 关于输入输出与人类的交互流程

系统的输入输出完全通过其Web前端界面与用户进行交互。以下是完整的交互路径：

输入 (Input):

动作: 用户通过前端界面 (src/components/ai-generator/MultiFileUpload.tsx 组件) 上传文件。

人类交互: 用户将本地的Axure导出文件夹（包含.html和.js文件）拖拽到上传区域，或通过文件选择器选取。同时，在表单中输入“系统名称”、“模块名称”等文本信息。

中间输出 / 交互 (Intermediate Output / Interaction):

动作: 系统完成解析后，输出AI生成的需求文档初稿。

人类交互: 用户在网页上的一个富文本编辑器（src/components/ai-generator/MarkdownEditor.tsx）中阅读和编辑这份Markdown格式的文档。这是第一个关键的人机交互审核点。

最终输出 / 交互 (Final Output / Interaction):

动作: 在用户确认需求文档后，系统在“草稿箱”区域以卡片形式（src/components/ai-generator/DraftCaseCard.tsx）分批输出生成的测试用例。

人类交互: 用户浏览这些卡片，通过点击复选框进行选择。如果需要修改，可以点击卡片打开一个模态框（src/components/ai-generator/TestCaseDetailModal.tsx）来编辑测试点的具体步骤和预期结果。这是第二个关键的人机交互审核点。

持久化 (Persistence):

动作: 用户完成选择和编辑后，点击“保存到用例库”按钮。

人类交互: 单次点击操作，触发数据持久化。

最终结果展示 (Final Result Display):

动作: 系统将用户保存的测试用例持久化到数据库后，通常会跳转到功能测试用例列表页面 (/functional-test-cases)。

人类交互: 用户在该页面以表格或列表的形式，查看已成为正式记录的、可供后续使用的测试用例。

4. 关于用户系统、角色与权限

肯定回答：系统具备完整的用户登录、角色与权限管理机制。

4.1 用户登录系统

存在性: 是。文件结构中明确包含用户认证相关模块：

server/routes/auth.ts (登录API路由)

server/services/authService.ts (登录逻辑服务)

src/pages/Login.tsx (前端登录页面)

src/contexts/AuthContext.tsx (前端认证状态管理)

机制: 系统基于JWT (JSON Web Token) 实现会话管理。用户登录成功后，前端会存储一个token用于后续所有API请求的身份验证。

4.2 目标用户角色

主要用户: 根据需求文档 docs/tech-docs/Axure自动生成测试用例-需求文档-V2.0-最终版.md 中的“1.4 用户角色”章节定义，系统的主要用户是测试工程师、QA工程师。

次要用户: 产品经理和开发工程师被定义为次要用户，他们可以使用系统来了解测试覆盖范围和测试场景。

4.3 角色与权限

存在性: 是。系统定义了不同级别的权限，主要体现在数据隔离上。

证据:

数据库层面: prisma/schema.prisma 文件中的 users 表定义了 is_super_admin (布尔型) 字段，表明存在超级管理员角色。同时，users, test_cases, functional_test_cases 等多个表都包含 department (部门) 字段，这是实现数据隔离的基础。

代码层面: 后端路由和服务中存在基于用户角色和部门进行数据过滤的逻辑。例如，在获取测试用例列表时，会检查用户是否为 isSuperAdmin。如果不是，查询将额外附加 WHERE department = '用户的部门' 的条件。

定义的角色:

超级管理员 (Super Admin): 拥有最高权限，可以查看和管理所有部门的测试数据。

普通用户 (Regular User): 权限受其所属 department 字段限制，只能查看和管理自己所在部门的测试用例和测试套件。